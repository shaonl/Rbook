{
  "hash": "af29088f923b1e43a6e51f3fb367a666",
  "result": {
    "markdown": "# Importing Data {#sec-dataimp}\n\n## Importing a CSV or Excel file\n\nPeople often store data in a spreadsheet. That makes a lot of sense since a spreadsheet has rows and columns, and that's how most of our data in social science is going to be organized. It's very easy to import spreadsheet data into R.\n\nTo begin, let's be clear on the difference between **Comma Separated Values (CSV)** files and Microsoft's proprietary **Excel file formats (xls or xlsx)**. CSV files are a plain text format which separates a series of values with commas. Plain text means it cannot store formatting, macros, formulas, or other things that you might see in other file formats. You can open a CSV file in Microsoft Excel, but you cannot open an Excel file in a text editor. So, in general CSV files are probably the way to go in terms of storing data since they can be easily opened and manipulated, but Excel files are pretty great because they contain meta-data files, [which can help detect instances of data tampering](https://datacolada.org/109)!\n\nLet's go ahead and import the data using the `read.csv()` function, and assign the dataframe to an object called `mydata1`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# This is how to import a CSV file from a URL\nmydata1 <- read.csv(\"https://data.kingcounty.gov/api/views/yaai-7frk/rows.csv?accessType=DOWNLOAD\")\n\n# To import a CSV file that you have downloaded, just put the path in where the URL went above. \n# If you're on Windows like me, make sure the backslahes are doubled up like this \\\\. \n# You can also change them to single forward slashes /. \n\nmydata1 <- read.csv(\"~/R Book/Datasets/Lost__found__adoptable_pets.csv\")\n```\n:::\n\n\n\nLet's start out by getting a sense of the scale of the dataframe using the dimensions `dim()` function. Then, let's check very quickly that the data look ok (i.e. there arent's any weird anomalies that jump out) by using the `View()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndim(mydata1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 540  25\n```\n:::\n:::\n\n\n\nUsing the `dim()` function, we can see that there are 528 rows and 25 columns in the dataframe. Each row corresponds to a unit of observation, and each column corresponds to a different variable. So, this dataframe has 528 units of observation, and 25 variables.\n\nCool, now let's take a closer look at the data with the `View()` function.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nView(mydata1)\n```\n:::\n\n\n\n![](/Images/dogsdf.png)\n\nOk, it looks like we have a variables corresponding to whether the dog is lost, found, or adoptable (`Record_type`), the specific ID of the animal (`Animal_ID`), it's current location, and several others. It's always a good idea to have a look at the data to see if anything looks amiss. We'll get more into some specifics of data cleaning a bit later, but for now, it's worthwhile just having a look.\n\nYou can import an Excel file easily into R using the `readxl` package. The corresponding `read_xls()` and `read_xlsx()` functions will help you import .xls (older Excel files) and .xlsx files, respectively. The main argument is the file path.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(readxl)\n\n# Read a Microsoft Excel file.\n\ndf1 <- read_xlsx(\"~/R Book/Datasets/Lost__found__adoptable_pets_excel.xlsx\")\n```\n:::\n\n\n\n## Importing a text file\n\nTo import a text file (a file with the extension .txt), we first need to know how data are separated. Usually, this is done by tabs (think of the 'tab' key on your keyboard). In such cases, the `read.table()` function is useful where the arguments should be the URL or file path, followed by the type of separator using the `sep =` argument. For tabs, it should be `sep = '\\t'`. For comma-separated data, it should be `sep = ','` and for period-separated data, it should be `sep = '.'`. Since, this data frame is tab-separated (I know because I saved it as such), we will use the tab separator.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read a tab-separated text file.\nmydata2 <- read.table(\"~/R Book/Datasets/zoo.txt\", sep = '\\t')\n\ndim(mydata2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 44 18\n```\n:::\n:::\n\n\n\nUsing the `dim()` function, we can see that this dataframe has 44 units of observation and 18 variables. While we can always use the `View()` function to have a look at the data, let's say that we're in a real hurry and we just want to look at the first 10 rows of the data. Recall, that we can use `head()` function, and specify `n = 10` to look at the first 10 rows.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(mydata2, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            V1   V2       V3   V4   V5       V6      V7       V8      V9\n1  animal_name hair feathers eggs milk airborne aquatic predator toothed\n2       turtle    0        0    1    0        0       1        0       0\n3    chameleon    0        0    1    0        0       0        0       1\n4       iguana    0        0    1    0        0       0        1       1\n5       lizard    0        0    1    0        0       0        1       1\n6        gecko    0        0    1    0        0       0        0       1\n7       python    0        0    1    0        0       0        1       1\n8          boa    0        0    1    0        0       0        1       1\n9        adder    0        0    1    0        0       0        1       1\n10   crocodile    0        0    1    0        0       1        1       1\n        V10      V11      V12  V13  V14  V15      V16     V17        V18\n1  backbone breathes venomous fins legs tail domestic catsize class_type\n2         1        1        0    0    4    1        1       1          3\n3         1        1        0    0    4    1        1       0          3\n4         1        1        0    0    4    1        1       1          3\n5         1        1        0    0    4    1        0       0          3\n6         1        1        0    0    4    1        1       0          3\n7         1        1        1    0    0    1        0       1          3\n8         1        1        0    0    0    1        0       1          3\n9         1        1        1    0    0    1        0       1          3\n10        1        1        0    0    4    1        0       1          3\n```\n:::\n:::\n\n\n\nUh oh, it looks like the first row of data is the name of the variables! That's no good. The solution is simply to include the argument `header = TRUE` in the `read.table()` function. So let's try that data import of a text file again with the new argument.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Read a tab-separated text file and keep the headers.\nmydata2 <- read.table(\"~/R Book/Datasets/zoo.txt\", sep = '\\t', header = TRUE)\n\ndim(mydata2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 43 18\n```\n:::\n:::\n\n\n\nThe `dim()` function now shows me the dataframe has one less row than before (44 to 43). That's good! Now, let's use the `head()` function to check if the variable names are correctly excluded from our rows.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhead(mydata2, n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   animal_name hair feathers eggs milk airborne aquatic predator toothed\n1       turtle    0        0    1    0        0       1        0       0\n2    chameleon    0        0    1    0        0       0        0       1\n3       iguana    0        0    1    0        0       0        1       1\n4       lizard    0        0    1    0        0       0        1       1\n5        gecko    0        0    1    0        0       0        0       1\n6       python    0        0    1    0        0       0        1       1\n7          boa    0        0    1    0        0       0        1       1\n8        adder    0        0    1    0        0       0        1       1\n9    crocodile    0        0    1    0        0       1        1       1\n10   alligator    0        0    1    0        0       1        1       1\n   backbone breathes venomous fins legs tail domestic catsize class_type\n1         1        1        0    0    4    1        1       1          3\n2         1        1        0    0    4    1        1       0          3\n3         1        1        0    0    4    1        1       1          3\n4         1        1        0    0    4    1        0       0          3\n5         1        1        0    0    4    1        1       0          3\n6         1        1        1    0    0    1        0       1          3\n7         1        1        0    0    0    1        0       1          3\n8         1        1        1    0    0    1        0       1          3\n9         1        1        0    0    4    1        0       1          3\n10        1        1        0    0    4    1        0       1          3\n```\n:::\n:::\n\n\n\nThat's better! Always be mindful of the \"header problem\" wherein the headers get mistakenly included as observational units, rather than column labels.\n\n## Importing a Stata, SAS, or SPSS file\n\nRecall from @tbl-statsprogs that Stata, SAS, and SPSS are different proprietary programs for statistical analysis. Stata is very commonly used by economists, and others in the social sciences. SAS is commonly used by healthcare and goverment agencies. SPSS is a commonly used by psychologists and other social scientists. Sometimes you might be working with someone who uses one of these software programs, or need to import a dataset from one of these programs.\n\nFirst, it's important to know the file extension for each software program. Once you know the appropriate format, the `haven` package will allow us to import data from SAS, SPSS, or Stata into R. That's pretty cool and easy! These can be found in @tbl-progsdata\n\n| Software | File Extension    | Relevant *haven* package function |\n|----------|:------------------|-----------------------------------|\n| SPSS     | .sav              | `read_sav()`                      |\n| SAS      | .sas7bdat or .xpt | `read_sas()` or `read_xpt()`      |\n| Stata    | .dta              | `read_dta()`                      |\n\n: Data file extensions for Stata, SAS, or SPSS and the relevant *haven* package function. {#tbl-progsdata}\n\nLet's give each of these a shot with the relevant data format. Remember to install the `haven` package if you haven't done that already with `install.packages(\"haven\")` and then load the package using `library(haven)`.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\n# Read a sas7bdat file.\nmydata3 <- read_sas(\"~/R Book/Datasets/naws_all.sas7bdat\")\n```\n:::\n\n\n\nWhen a SAS data file is exported, you may see the file extension .xpt. As seen in @tbl-progsdata, this is not a problem for the formidable `haven` package. Let's import an XPT file now.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(haven)\n\n# Read a SAS xpt file.\nmydata4 <- read_xpt(\"~/R Book/Datasets/P_DEMO.xpt\")\n\ndim(mydata4)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 15560    29\n```\n:::\n:::\n\n\n\nWe can see that the data frame has 15,560 observational units and 29 columns or variables. Let's have a look at the last 10 rows of data and first 6 columns.\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntail(mydata4[, c(1:6)], n = 10)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 10 x 6\n     SEQN SDDSRVYR RIDSTATR RIAGENDR RIDAGEYR RIDAGEMN\n    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>    <dbl>\n 1 124813       66        2        2       43       NA\n 2 124814       66        2        1       64       NA\n 3 124815       66        2        1       52       NA\n 4 124816       66        2        1        1       15\n 5 124817       66        2        2       67       NA\n 6 124818       66        2        1       40       NA\n 7 124819       66        2        1        2       NA\n 8 124820       66        2        2        7       NA\n 9 124821       66        2        1       63       NA\n10 124822       66        2        1       74       NA\n```\n:::\n:::\n\n\n\nWe can see a number of variables with values, and things seem to have imported nicely. We can't know this for sure until we've done some more careful examination and cleaning of the data, but the fact that nothing looks terribly out of place at first glance is a good sign.\n\nYou will also notice that when we examined the first and last 10 rows and first six columns, R gave us a **tibble** of dimensions 10 \\* 6. A tibble is basically a well-formatted and easy to understand summary of the data in R. Tibbles print data out nicely so they're easy to glance at.\n\nNow you know how to import a number of common data types into R! So, why not...\n\n[![Manx cat has public use dataset suggestions for you if you just click on him. Credit to the University of Missouri Libraries.](/Images/manx2.png){fig-align=\"left\"}](https://libraryguides.missouri.edu/datasets/public-use)\n",
    "supporting": [
      "dataimport_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {
      "knitr": [
        "{\"type\":\"list\",\"attributes\":{},\"value\":[]}"
      ]
    },
    "preserve": null,
    "postProcess": false
  }
}