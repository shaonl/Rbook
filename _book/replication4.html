<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.353">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Research Transparency, Reproducibility, and Basic Data Analysis in R! - 15&nbsp; Crises of Replication</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./replication5.html" rel="next">
<link href="./replication3.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 20,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit"
  }
}</script>

  <script>window.backupDefine = window.define; window.define = undefined;</script><script src="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.js"></script>
  <script>document.addEventListener("DOMContentLoaded", function () {
 var mathElements = document.getElementsByClassName("math");
 var macros = [];
 for (var i = 0; i < mathElements.length; i++) {
  var texText = mathElements[i].firstChild;
  if (mathElements[i].tagName == "SPAN") {
   katex.render(texText.data, mathElements[i], {
    displayMode: mathElements[i].classList.contains('display'),
    throwOnError: false,
    macros: macros,
    fleqn: false
   });
}}});
  </script>
  <script>window.define = window.backupDefine; window.backupDefine = undefined;</script><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.1/dist/katex.min.css">

</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
      <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./replication4.html"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Crises of Replication</span></a></li></ol></nav>
      <a class="flex-grow-1" role="button" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
      </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">Research Transparency, Reproducibility, and Basic Data Analysis in R!</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text">Preface</span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./installation.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">1</span>&nbsp; <span class="chapter-title">Installing R and RStudio</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./getstarted.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">2</span>&nbsp; <span class="chapter-title">Getting Accustomed to R Studio</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./intro.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">3</span>&nbsp; <span class="chapter-title">Introduction to R</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datatypes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">4</span>&nbsp; <span class="chapter-title">Data Types</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./stringscomps.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">5</span>&nbsp; <span class="chapter-title">Strings &amp; Comparisons</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataimport.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">6</span>&nbsp; <span class="chapter-title">Importing Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./datajoin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">7</span>&nbsp; <span class="chapter-title">Merging (Joining) and Reshaping Data</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./cleaning.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">8</span>&nbsp; <span class="chapter-title">Data Cleaning</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataexp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">9</span>&nbsp; <span class="chapter-title">Data Exploration with <code>dplyr</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataviz.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">10</span>&nbsp; <span class="chapter-title">Data Visualization with base R and <code>ggplot2</code></span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./dataanalysis.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">11</span>&nbsp; <span class="chapter-title">Univariate, Bivariate &amp; Multivariable Analysis</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./replication1.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">12</span>&nbsp; <span class="chapter-title">A Very Brief History of Replication</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./replication2.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">13</span>&nbsp; <span class="chapter-title">Mertonian Norms and Counter-Norms</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./replication3.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Some Statistical Preliminaries</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./replication4.html" class="sidebar-item-text sidebar-link active">
 <span class="menu-text"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Crises of Replication</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./replication5.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Common Problems that Hamper Reproducibility</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./replication6.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">17</span>&nbsp; <span class="chapter-title">Potential Solutions &amp; the Way Forward</span></span></a>
  </div>
</li>
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./references.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">18</span>&nbsp; <span class="chapter-title">References</span></span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true">
 <span class="menu-text">Appendices</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appintroex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">A</span>&nbsp; <span class="chapter-title">Answers for </span></span></a><a href="intro.html#sec-introex"><span>Section&nbsp;3.8</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appdatatypes.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">B</span>&nbsp; <span class="chapter-title">Answers for </span></span></a><a href="datatypes.html#sec-dtex"><span>Section&nbsp;4.7</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appstringcomp.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">C</span>&nbsp; <span class="chapter-title">Answers for </span></span></a><a href="stringscomps.html#sec-sboex"><span>Section&nbsp;5.3</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appdatajoin.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">D</span>&nbsp; <span class="chapter-title">Answers for </span></span></a><a href="datajoin.html#sec-joinex"><span>Section&nbsp;7.5</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appdataclean.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">E</span>&nbsp; <span class="chapter-title">Answers for </span></span></a><a href="cleaning.html#sec-cleanex"><span>Section&nbsp;8.8</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./apptidyex.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">F</span>&nbsp; <span class="chapter-title">Answers for </span></span></a><a href="dataexp.html#sec-tidyex"><span>Section&nbsp;9.5</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./appkahneman.html" class="sidebar-item-text sidebar-link">
 <span class="menu-text"><span class="chapter-number">G</span>&nbsp; <span class="chapter-title">Kahneman’s Open Letter to Priming Researchers</span></span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar,#quarto-sidebar-glass"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#reproducibility-and-replication-definitions" id="toc-reproducibility-and-replication-definitions" class="nav-link active" data-scroll-target="#reproducibility-and-replication-definitions"><span class="header-section-number">15.1</span> Reproducibility and Replication Definitions</a></li>
  <li><a href="#stirrings-of-a-crisis" id="toc-stirrings-of-a-crisis" class="nav-link" data-scroll-target="#stirrings-of-a-crisis"><span class="header-section-number">15.2</span> Stirrings of a Crisis</a></li>
  <li><a href="#feeling-the-future" id="toc-feeling-the-future" class="nav-link" data-scroll-target="#feeling-the-future"><span class="header-section-number">15.3</span> Feeling the Future</a>
  <ul class="collapse">
  <li><a href="#an-unintentional-crisis-unfolds" id="toc-an-unintentional-crisis-unfolds" class="nav-link" data-scroll-target="#an-unintentional-crisis-unfolds"><span class="header-section-number">15.3.1</span> An Unintentional Crisis Unfolds</a></li>
  <li><a href="#where-bem-went-wrong" id="toc-where-bem-went-wrong" class="nav-link" data-scroll-target="#where-bem-went-wrong"><span class="header-section-number">15.3.2</span> Where Bem Went Wrong</a></li>
  </ul></li>
  <li><a href="#the-domino-effect" id="toc-the-domino-effect" class="nav-link" data-scroll-target="#the-domino-effect"><span class="header-section-number">15.4</span> The Domino Effect</a></li>
  <li><a href="#gauging-the-extent-of-the-damage" id="toc-gauging-the-extent-of-the-damage" class="nav-link" data-scroll-target="#gauging-the-extent-of-the-damage"><span class="header-section-number">15.5</span> Gauging the Extent of the Damage</a>
  <ul class="collapse">
  <li><a href="#the-open-science-collaboration" id="toc-the-open-science-collaboration" class="nav-link" data-scroll-target="#the-open-science-collaboration"><span class="header-section-number">15.5.1</span> The Open Science Collaboration</a></li>
  <li><a href="#questionable-research-practices-in-psychology" id="toc-questionable-research-practices-in-psychology" class="nav-link" data-scroll-target="#questionable-research-practices-in-psychology"><span class="header-section-number">15.5.2</span> Questionable Research Practices in Psychology</a></li>
  <li><a href="#many-labs-2" id="toc-many-labs-2" class="nav-link" data-scroll-target="#many-labs-2"><span class="header-section-number">15.5.3</span> Many Labs 2</a></li>
  <li><a href="#replicating-social-science-experiments-from-nature-and-science" id="toc-replicating-social-science-experiments-from-nature-and-science" class="nav-link" data-scroll-target="#replicating-social-science-experiments-from-nature-and-science"><span class="header-section-number">15.5.4</span> Replicating Social Science Experiments from <em>Nature</em> and <em>Science</em></a></li>
  </ul></li>
  <li><a href="#retractions" id="toc-retractions" class="nav-link" data-scroll-target="#retractions"><span class="header-section-number">15.6</span> Retractions</a>
  <ul class="collapse">
  <li><a href="#what-is-it-and-why-does-it-happen" id="toc-what-is-it-and-why-does-it-happen" class="nav-link" data-scroll-target="#what-is-it-and-why-does-it-happen"><span class="header-section-number">15.6.1</span> What is it, and Why Does it Happen?</a></li>
  <li><a href="#life-after-death-continued-citations-despite-retraction" id="toc-life-after-death-continued-citations-despite-retraction" class="nav-link" data-scroll-target="#life-after-death-continued-citations-despite-retraction"><span class="header-section-number">15.6.2</span> Life After Death: Continued Citations Despite Retraction</a></li>
  </ul></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title"><span id="sec-rep4" class="quarto-section-identifier"><span class="chapter-number">15</span>&nbsp; <span class="chapter-title">Crises of Replication</span></span></h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="reproducibility-and-replication-definitions" class="level2" data-number="15.1">
<h2 data-number="15.1" class="anchored" data-anchor-id="reproducibility-and-replication-definitions"><span class="header-section-number">15.1</span> Reproducibility and Replication Definitions</h2>
<p>Let’s remind ourselves what Reproducibility and Replicability mean. As you see in <a href="#fig-rep3">Figure&nbsp;<span>15.1</span></a>, Reproducibility involves literally reproducing the results from a study using original data, code, and materials. Replicability is about carrying out the study using the same procedures in different settings and achieving consistent, not identical, results.</p>
<div id="fig-rep3" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/rep.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.1: Reproducibility and Replicability.</figcaption>
</figure>
</div>
</section>
<section id="stirrings-of-a-crisis" class="level2" data-number="15.2">
<h2 data-number="15.2" class="anchored" data-anchor-id="stirrings-of-a-crisis"><span class="header-section-number">15.2</span> Stirrings of a Crisis</h2>
<p>For a long time, there was concern about the replicability and reproducibility of findings in the social sciences. In 2005, physician-scientist John Ioannidis published a provocative and worrying essay entitled <a href="https://upload.wikimedia.org/wikipedia/commons/8/8e/Ioannidis_%282005%29_Why_Most_Published_Research_Findings_Are_False.pdf"><em>Why Most Published Research Findings are False</em></a>, which outlined several methodological shortcomings plaguing most published research using statistics, including an over-reliance on p-values, low statistical power, and biases in study design, data collection, and analysis.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/mostfalse.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Ioannidis laid out several factors why most published research is false.<span class="citation" data-cites="ioannidis_why_2005"><sup><a href="references.html#ref-ioannidis_why_2005" role="doc-biblioref">1</a></sup></span></figcaption>
</figure>
</div>
<p>He noted that several biases in design, data analysis, and presentation factors influence the production of research findings. With greater bias in the conduct of a study, the lower the chances of the research finding being true. Additionally, the likelihood of a finding being true depends a great deal on the pre-study odds of it being true, as well as the statistical power of a study. He also points out that when a study is replicated by others in different contexts, the effect size is also likely to be smaller, and the likelihood of the finding being true is diminished.</p>
<p>This obviously made a lot of folks nervous, and become a highly downloaded paper. However, the concerns about replication did not truly become mainstream until one particular psychologist from Cornell published a study suggesting that humans have psychic ability…</p>
</section>
<section id="feeling-the-future" class="level2" data-number="15.3">
<h2 data-number="15.3" class="anchored" data-anchor-id="feeling-the-future"><span class="header-section-number">15.3</span> Feeling the Future</h2>
<section id="an-unintentional-crisis-unfolds" class="level3" data-number="15.3.1">
<h3 data-number="15.3.1" class="anchored" data-anchor-id="an-unintentional-crisis-unfolds"><span class="header-section-number">15.3.1</span> An Unintentional Crisis Unfolds</h3>
<p>In 2011, a study authored by Cornell psychologist Daryl Bem (a very respected psychologist) was published in the <em>Journal for Personality and Social Psychology</em> (a very respected psychology journal). The study appeared to shake the foundations of what we know about human beings. It suggested, through a series of nine experiments comprising more than 1,000 participants over ten years that humans have psychic ability!</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/bem2.jpg" class="img-fluid figure-img" width="485"></p>
<figcaption class="figure-caption">Former Cornell professor of psychology Daryl Bem was very interested in studying the paranormal. Perhaps he wanted to find evidence for the paranormal a little too much.</figcaption>
</figure>
</div>
<p>Here’s what happened. Bem administered College students came to a computer lab, and had to look at a computer screen. He administered many experiments to see if people have an innate psychic ability to predict the future. In one experiment, participants were presented with two curtains on a screen (represented in Figure <a href="#fig-curtain">Figure&nbsp;<span>15.2</span></a> below).</p>
<div id="fig-curtain" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/curtains.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.2: Participants had to guess which one curtain concealed an image. After they made their guess, the image was randomly assigned to one curtain or another.</figcaption>
</figure>
</div>
<p>They had to then guess which curtain was concealing an image. Unbeknownst to them, the image would be randomly allocated to a curtain <em>after</em> they had made their choice. So, if they were able to guess which curtain held the image better than a 50-50 chance (for example, say they correctly guessed 60% of the time), this would be taken as evidence of an extra-sensory perception that allows one to <em>Feel the Future</em> (the admittedly catchy title of the study). Notably, some of the images were ‘erotic’ in nature, while others were neutral. In eight of nine studies reported in the paper, participants were significantly likely to predict which curtain contained the image. The findings in totality provided Bem ample evidence for the anomalous phenomenon of precognition, or psychic ability to see the future.</p>
<p>The study became <strong>HUGE</strong>. In general, if more than ten people read your research, I would call that a win. But Bem’s study was a darling of the media. The <em>New York Times</em> ran a front-page story on it, and Bem even appeared on the popular comedy program <em>The Colbert Report</em>. Those who were already convinced of the <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2020.562992/full">highly questionable field</a> of <em>Psi</em> research (research on paranormal phenomena) were thrilled at Bem’s study. It seemed to provide strong evidence for psychic ability using widely accepted methods in a respected journal by a respected Ivy-league professor. Bem had large enough sample sizes to be accepted by the journal (he had been the Editor previously so he knew his methods were up to snuff), used basic one sample t-tests that one learns in introductory statistics classes, and made sure his stimuli had been randomized correctly. Many began to question whether humans had psychic ability based on Bem’s findings, and I don’t blame them at all. In the words of Slate author Daniel Engber, Bem’s findings were both <em>methodologically sound and logically insane.</em><span class="citation" data-cites="engber_daryl_2017"><sup><a href="references.html#ref-engber_daryl_2017" role="doc-biblioref">2</a></sup></span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/nytbem.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Bem’s ESP study riled up the field of social psychology…and beyond!</figcaption>
</figure>
</div>
<p>So, do humans actually have psychic ability? No.&nbsp;At least, we don’t actually have any convincing evidence for that notion. Others tried to replicate Bem’s findings and did not find the same effects. In fact, one large replication with 3,289 participants across seven experiments found an effect size of <span class="math inline">d = 0.04</span>, which is statistically indistinguishable from zero. In another very thorough replication study involving 2,115 participants and ten labs from nine different countries, the researchers were unable to replicate Bem’s parapsychological effects, and found support for the notion that Bem’s statistically significant findings were <em>pure bias</em> in that significant findings were due to researcher and publications biases, as well as a lack of methodological rigor.<span class="citation" data-cites="kekecs_raising_2023"><sup><a href="references.html#ref-kekecs_raising_2023" role="doc-biblioref">3</a></sup></span></p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bem fires back.
</div>
</div>
<div class="callout-body-container callout-body">
<p>I should note that Bem tried to dispute the findings of the skeptics with a meta-analysis of 90 studies from 33 labs across 14 countries suggesting that this findings are in fact real.<span class="citation" data-cites="bem_feeling_2016"><sup><a href="references.html#ref-bem_feeling_2016" role="doc-biblioref">4</a></sup></span> However, given the myriad problems in the conduct and reporting of studies observed in the original study by Bem, I think it’s fair to say most academics in the field didn’t really buy these updated findings. Indeed, a breakdown of the statistics in the meta-analysis raises more questions than it answers.<span class="citation" data-cites="lakens_20_2014"><sup><a href="references.html#ref-lakens_20_2014" role="doc-biblioref">5</a></sup></span> Given the replication work by non-Bem affiliated labs, and the fact that they are more recent, it’s safe to conclude that the original findings are not supported (however much some might want them to be).</p>
</div>
</div>
</section>
<section id="where-bem-went-wrong" class="level3" data-number="15.3.2">
<h3 data-number="15.3.2" class="anchored" data-anchor-id="where-bem-went-wrong"><span class="header-section-number">15.3.2</span> Where Bem Went Wrong</h3>
<p>Ok, so you may be wondering, “Well what did Bem do wrong?” He used widely accepted statistical methods, used large sample sizes, performed multiple experiments across years, and went through peer-review in a top-tier journal. It would seem he did everything right! The lesson is instructive, because you can do all of that, and still produce junk science. Bem fell prey to what we now call <strong>Researcher Degrees of Freedom</strong> - the flexibility inherent in the many decisions researchers have to make in data collection, analysis, and reporting that can result in selective practices producing spurious results.<span class="citation" data-cites="simmons_false-positive_2011"><sup><a href="references.html#ref-simmons_false-positive_2011" role="doc-biblioref">6</a></sup></span> Engaging in researcher degrees of freedom increases the chance of false positives, or Type I errors, as well as biases in selectively reporting only findings that confirm one’s pre-existing conceptions. Here are just two researcher degrees of freedom that very likely led Bem to his spurious findings:</p>
<ul>
<li><p><strong>Bem made many tweaks to his experiments over the years in order to yield statistically significant results.</strong> He did not document many of them. If you tweak your experiments without reporting that you did so, you make it seem like you just got the result magically, and not as a result of careful manipulation. This manipulation can results in false positives, but it also weakens your conceptual theory. For example, if a study did not show evidence of psychic ability, and Bem modified the experiment, and then DID find evidence of psychic ability, what does this say about his theory of psychic ability. In this way, notice how you can get very flexible with your theory if you’re making undocumented tweaks.</p></li>
<li><p><strong>There were no pre-registered replications of experiments in Bem’s original study.</strong> While we’ll get to pre-registration a bit more in detail later, the idea is simple: 1) Before you do your study, say what your going to do, why, and how; 2) publish this <em>pre-registration</em> in the public domain; 3) do your study and report back on the things you had planned to do. Nowadays, this is a common rigorous practice, but was not really a thing in Bem’s time. This means that after doing one experiment, Bem was free to plan, adapt, abandon, and modify his hypotheses and experimental protocols in order to yield statistically significant results. Thus, if he ran a study, didn’t find what he wanted and then abandoned the study, this would not be recorded. Selective reporting means that you could run 100 studies, and only report and publish 10 of those that are statistically significant, severely distorting the evidence base and hiding your 90% null results rate.</p></li>
</ul>
<p>Bem’s own words in an interview with Slate magazine in 2017 are quite instructive:</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Bem in his own words.
</div>
</div>
<div class="callout-body-container callout-body">
<p>“I would start one [experiment], and if it just wasn’t going anywhere, I would abandon it and restart it with changes,” Bem told me recently. Some of these changes were reported in the article; others weren’t. “I didn’t keep very close track of which ones I had discarded and which ones I hadn’t,” he said. Given that the studies spanned a decade, Bem can’t remember all the details of the early work. “I was probably very sloppy at the beginning,” he said. “I think probably some of the criticism could well be valid. I was never dishonest, but on the other hand, the critics were correct.”<span class="citation" data-cites="engber_daryl_2017"><sup><a href="references.html#ref-engber_daryl_2017" role="doc-biblioref">2</a></sup></span></p>
</div>
</div>
</section>
</section>
<section id="the-domino-effect" class="level2" data-number="15.4">
<h2 data-number="15.4" class="anchored" data-anchor-id="the-domino-effect"><span class="header-section-number">15.4</span> The Domino Effect</h2>
<p>After the publication of Bem’s ESP paper, many began questioning the foundations of the entire field of social psychology. Researchers began <strong>trying and failing</strong> to replicate many classic findings in psychology. The subfield of priming within social psychology was one of the first fields to undergo extensive critical scrutiny, with some dire results. Many priming studies failed to replicate, and it seemed that faulty methods, lack of statistical power, researcher biases, and publication biases were responsible.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
A Prime Candidate for Replication: The Elderly Priming Study.
</div>
</div>
<div class="callout-body-container callout-body">
<p>For instance, a classic study in the field of subliminal priming led by Yale psychologist John Bargh involved one experiment in which undergraduates in a lab worked on a scrambled-sentence task. That is, they were given 30 sets of five word combinations which they had to use to construct a sentence. In the treatment group, the scrambled words contained words previously identified to be related to stereotypes of the elderly: <em>Florida, old, lonely, grey, sentimental, wise,</em> etc. (these are from the actual study). The hidden outcome of this study was the time it took for participants to walk down a corridor to leave the study area. The results showed that those exposed to the elderly prime condition walked almost one second slower than those who were exposed to neutral words (a statistically significant result).<span class="citation" data-cites="bargh_automaticity_1996"><sup><a href="references.html#ref-bargh_automaticity_1996" role="doc-biblioref">7</a></sup></span></p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/bemgraphic.png" class="img-fluid figure-img" width="452"></p>
</figure>
</div>
<p>Sounds pretty cool right? That’s certainly what the authors of a psychology textbook I read in college thought when they presented the results of this study as fact. Unfortunately for Bargh and his colleagues, the unintentional crisis of replication set in motion by Bem led a team to try and replicate the classic elderly prime findings. The team followed the same protocol as Bargh and his colleagues, and found no difference in walking times between the elderly and neutral prime conditions.<span class="citation" data-cites="doyen_behavioral_2012"><sup><a href="references.html#ref-doyen_behavioral_2012" role="doc-biblioref">8</a></sup></span></p>
<p>Notably, the replication team used infrared sensors to automate the timing process, so it didn’t depend on a human’s use of a stopwatch. They speculated that the people manually timing the participants may have been a source of bias in the original study. They ran another experiment in which they used people to manually time participants with a stopwatch (I’ll call them the <em>timers</em>). They told the timers in one group that participants in the treatment group would walk faster, and they told the other half the participants in the treatment group would walk slower. Unbeknownst to the timers, infrared sensors were also measuring participants’ objective walking speeds. The results showed that when experimenters were led to believe participants would walk slower as a result of the intervention, the walking times were significantly higher in the Prime condition compared to the Neutral condition. Interestingly, when experimenters were led to believe that participants would walk <em>faster</em> as a result of the intervention, the walking times were significantly lower in the Prime condition compared to the Neutral condition. The results suggest that priming effects may reflect experimenter bias, rather than an actual induced effect of a prime stimulus on participants.</p>
<p>I should note that some of Bargh’s other priming studies have also failed to replicate.<span class="citation" data-cites="schimmack_replicability_2019"><sup><a href="references.html#ref-schimmack_replicability_2019" role="doc-biblioref">9</a></sup></span> For his part, Bargh dismissed the replication of his elderly prime study, and responded to the replicators with many objections to their replications as well as a scathing personal attack on them.<span class="citation" data-cites="yong_failed_2012"><sup><a href="references.html#ref-yong_failed_2012" role="doc-biblioref">10</a></sup></span></p>
</div>
</div>
<p>It seems that 2011 was a watershed moment in the history of reproducibility and replication. A few key moments are worth mentioning. First, just about two months after <em>The New York Times</em> reported on Bem’s ESP study, a group of researchers submitted a study for publication entitled <em>False-Positive Psychology: Undisclosed Flexibility in Data Collection and Analysis Allows Presenting Anything as Significant.<span class="citation" data-cites="simmons_false-positive_2011"><sup><a href="references.html#ref-simmons_false-positive_2011" role="doc-biblioref">6</a></sup></span></em></p>
<p>This paper demonstrated with real experimental data how easy it was to achieve statistical significance for an impossible hypothesis. In their study, the authors experimentally demonstrate that listening to the song <em>When I’m Sixty-Four</em> by the Beatles, compared to the song <em>Kalimba</em> which came free with Windows 7, actually MADE participants younger. Think about that for a second. Obviously, listening to any song might make you feel younger or older, but the outcome I mean here is <em>actual</em> chronological age measured by one’s birth date. Even though the premise that listening to the Beatles will make you younger is obviously false, the authors show, with standard statistical methods, that it is possible to achieve a statistically significant result supporting the impossible claim at <span class="math inline">p &lt; .05</span>. There was no magic associated with this finding, it was achieved deliberately by engaging in researcher degrees of freedom such as using multiple dependent variables but reporting only the covariates that resulted in statistical significance, analyzing data before all data were collected, and not using a rule for when to stop collecting data.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/beatles.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Listening to the Beatles can make you younger! Not really, but with so much analytic flexibility, you can make an impossible hypothesis appear statistically significant.</figcaption>
</figure>
</div>
<p>As the field of priming research began to come into question, prominent psychologist Daniel Kahneman wrote an open letter to Bargh and others in the field of priming studies asking them to clean up their act. The entire letter can be found in <a href="appkahneman.html"><span>Appendix&nbsp;G</span></a>. The letter is prescient and instructive. Kahenman correctly predicting a <em>train wreck looming</em> which became the <em>Replication Crisis</em>, and his proposal to have a daisy chain setup of different labs replicating the same effect foreshadowed many large replication efforts to come.</p>
<p>Kahneman was not and is not a priming researcher, but he had some skin in the game vis-à-vis a popular book he published in 2011 entitled <em>Thinking Fast and Slow</em> which went on to become a <em>New York Times</em> bestseller. The book was a popular psychology piece in which Kahneman reviewed some of his major findings, as well as those of others, some of whom included priming researchers. As the replication crisis unfolded, it became apparent that many of the chapters referenced studies which later failed to replicate, his fourth chapter representing the chapter most riddled with references to spurious studies.<span class="citation" data-cites="schimmack_meta-scientific_2020"><sup><a href="references.html#ref-schimmack_meta-scientific_2020" role="doc-biblioref">11</a></sup></span></p>
<p>To his credit, Kahneman provided a thoughtful response to a blog scrutinizing the shaky studies he cited in his book. Kahneman replied as a comment to the blog admitting that he placed too much faith in underpowered studies, despite having published a paper previously about how researchers are often reliant on underpowered studies.</p>
<div class="quarto-figure quarto-figure-center">
<figure class="figure">
<p><img src="Images/kahneman.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Kahneman lauded a number of priming studies in his bestselling book that turned out to not replicate. To his credit, he admitted this publicly. <em>Retraction Watch.</em></figcaption>
</figure>
</div>
<p>The case of Kahneman, a prominent researcher who knew well enough the dangers of relying on small sample sizes, falling prey to the very thing he had critiqued is illustrative of the importance of <em>evidence-based</em> rather than <em>eminence-based</em> practice. It also showed the extent of the problem. Even Nobel Prize winners could make mistakes in promoting weakly supported or spurious findings.</p>
<p>The replication crisis was not confined to priming studies, nor to the field of psychology alone. The crisis became evident in fields such as economics, cancer biology, finance, artificial intelligence, nutrition, and more. Indeed, it continues to this day, as more and more fields are critically scrutinizing key findings.</p>
</section>
<section id="gauging-the-extent-of-the-damage" class="level2" data-number="15.5">
<h2 data-number="15.5" class="anchored" data-anchor-id="gauging-the-extent-of-the-damage"><span class="header-section-number">15.5</span> Gauging the Extent of the Damage</h2>
<p>The replication crisis has resulted in major efforts to replicate key findings across different fields. This process continues to unfold, but we can examine some salient examples.</p>
<section id="the-open-science-collaboration" class="level3" data-number="15.5.1">
<h3 data-number="15.5.1" class="anchored" data-anchor-id="the-open-science-collaboration"><span class="header-section-number">15.5.1</span> The Open Science Collaboration</h3>
<p>A huge replication study was convened by a group called the Open Science Collaboration involving 270 scientists from 17 countries, who selected 100 studies published in 2008 from top-tier psychology journals.<span class="citation" data-cites="open_science_collaboration_estimating_2015"><sup><a href="references.html#ref-open_science_collaboration_estimating_2015" role="doc-biblioref">12</a></sup></span> Of the 100 studies, 97 had a finding that was statistically significant at the 5% level (<span class="math inline">p &lt; .05</span>), and of the replications 35 of 97 studies had a finding at <span class="math inline">p &lt; .05</span>. The replication study effects were also about half as big as the original study effects. The distribution of original study effect sizes and replicated study effect sizes in presented in <a href="#fig-repsizes">Figure&nbsp;<span>15.3</span></a>.</p>
<div id="fig-repsizes" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/repsizes.jpeg" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.3: The diagonal line represents the case where the original effect size = the replicated effect size. Red dots represent non-significant results (<span class="math inline">p &gt; .05</span>), and green dots represent significant results (<span class="math inline">p &lt; .05</span>). The dotted line represents zero effect, and points below represent replicated effects in the opposite direction of the original study.<span class="citation" data-cites="open_science_collaboration_estimating_2015"><sup><a href="references.html#ref-open_science_collaboration_estimating_2015" role="doc-biblioref">12</a></sup></span></figcaption>
</figure>
</div>
<p>This was a massive effort that took four years to painstakingly gather data and replicate these experiments. The fact that about two-thirds of findings published in top-tier psychology journals did not replicate was concerning to many who took these findings as well-established. What did it mean for other findings? What did it mean for the entire field of psychology? Could other fields be affected?</p>
</section>
<section id="questionable-research-practices-in-psychology" class="level3" data-number="15.5.2">
<h3 data-number="15.5.2" class="anchored" data-anchor-id="questionable-research-practices-in-psychology"><span class="header-section-number">15.5.2</span> Questionable Research Practices in Psychology</h3>
<p>To better understand the extent of Questionable Research Practices (QRPs; researcher degrees of freedom) in psychology, a group of researchers surveyed over 2,000 academic psychologists at major US universities.<span class="citation" data-cites="john_measuring_2012"><sup><a href="references.html#ref-john_measuring_2012" role="doc-biblioref">13</a></sup></span> Respondents were asked about a) whether they had engaged in a number of QRPs (self-admission rate), b) the percentage of other psychologists they believed had engaged in the QRP (prevalence estimate), and c) the percentage of psychologists committing QRP who would admit to doing so. The main results are presented in <a href="#fig-johnstudy">Figure&nbsp;<span>15.4</span></a>.</p>
<div id="fig-johnstudy" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/johnstudy.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.4: For each QRP, the authors present the self-admission rate, the perceived prevalence of the QRP among other psychologists, and a prevalence estimate derived by the researchers taking the self-admission rate and dividing it by the estimate of how likely other psychologists would admit to engaging in QRPs.<span class="citation" data-cites="john_measuring_2012"><sup><a href="references.html#ref-john_measuring_2012" role="doc-biblioref">13</a></sup></span></figcaption>
</figure>
</div>
<p>As we see, even with a select sample of psychologists, many admitted to engaging in QRPs. We can imagine that the self-admission rate represents a potential underestimate of the true extent of the problem.</p>
</section>
<section id="many-labs-2" class="level3" data-number="15.5.3">
<h3 data-number="15.5.3" class="anchored" data-anchor-id="many-labs-2"><span class="header-section-number">15.5.3</span> Many Labs 2</h3>
<p>Imagine you replicate a study and find that the effects are different from the original. Immediately, the original authors may say that your protocol deviated from the original study, explaining the discrepancy in effect. To address this issue, a team carried out replications of 28 findings in psychology using protocols that were peer reviewed in advance.<span class="citation" data-cites="klein_many_2018"><sup><a href="references.html#ref-klein_many_2018" role="doc-biblioref">14</a></sup></span> Each protocol was administered on about 15,305 participants from 36 countries and territories. So, this was a series of high-powered replications. Remember that statistical power relates to having the ability to detect an effect if it’s actually there.</p>
<p>The team found that just 15 of 28 findings replicated in the same direction as the original at <span class="math inline">p &lt; .05</span>. Of these, 75% of the replicated findings were smaller than the original study effect. The authors concluded that the variation in effect sizes had more to do with the effect being studied than the sample or setting of the study.</p>
</section>
<section id="replicating-social-science-experiments-from-nature-and-science" class="level3" data-number="15.5.4">
<h3 data-number="15.5.4" class="anchored" data-anchor-id="replicating-social-science-experiments-from-nature-and-science"><span class="header-section-number">15.5.4</span> Replicating Social Science Experiments from <em>Nature</em> and <em>Science</em></h3>
<p>Moving from the field of psychology to social science broadly, a team replicated 21 experimental studies published in the top journals <em>Nature</em> and <em>Science</em> between 2010 and 2015.<span class="citation" data-cites="camerer_evaluating_2018"><sup><a href="references.html#ref-camerer_evaluating_2018" role="doc-biblioref">15</a></sup></span> By being published in these journals, one would assume that these experiments are rigorous and well conducted, as these journals are supposed to be at the forefront of science. The main results are presented in <a href="#fig-camerer">Figure&nbsp;<span>15.5</span></a>.</p>
<div id="fig-camerer" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/camererstudy.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.5: Standardized effect sizes presented such that 1 equals the original effect size. Yellow diamonds represent a zero effect, and green diamonds represent a statistically significant effect. Thirteen of 21 effects replicated in the same direction as the original study.<span class="citation" data-cites="camerer_evaluating_2018"><sup><a href="references.html#ref-camerer_evaluating_2018" role="doc-biblioref">15</a></sup></span></figcaption>
</figure>
</div>
<p>Despite being published in the BEST journals, eight of 21 studies did not replicate in the original direction, and the studies that did replicate were, on average, half the size of the original effect. Remember, getting published in these journals is very hard, and typically we expect robust effects to be found in their pages. The fact that a full eight of the 21 studies did not replicate, and that the replicated effects are much smaller than the original tells us that journal quality is not a failsafe for robust replicated findings. The authors conclude that both false positives, and inflated effect sizes of true positives contribute to <em>imperfect reproducibility</em>.</p>
</section>
</section>
<section id="retractions" class="level2" data-number="15.6">
<h2 data-number="15.6" class="anchored" data-anchor-id="retractions"><span class="header-section-number">15.6</span> Retractions</h2>
<section id="what-is-it-and-why-does-it-happen" class="level3" data-number="15.6.1">
<h3 data-number="15.6.1" class="anchored" data-anchor-id="what-is-it-and-why-does-it-happen"><span class="header-section-number">15.6.1</span> What is it, and Why Does it Happen?</h3>
<p>A journal will <strong>retract</strong> a paper when it removes a paper from its records that it already published. Retractions do not occur over small issues like typos. It’s usually something quite seriously wrong about the paper or the peer review process. Usually, retractions occur due to major errors in the research, plagiarism, data falsification, or something else quite serious. Authors can self-retract if they later discover a serious error in their work, and that’s a very laudable thing. However, quite often retraction decisions are made by the editor or editorial board of the journal.</p>
<p>Lack of reproducibility is usually not grounds for retraction on its own. Consider the Bem ESP study. Since its publication, we now have a pretty decent understanding of Bem’s spurious results, including testimony from Bem himself in committing what we now call researcher degrees of freedom. However, when the editor of the <em>Journal of Personality and Social Psychology</em> was asked to retract the study in 2018, it took him two years to respond to the letter and inform the requester that the paper would not be retracted. Thus, it’s not a done deal even when you have a false hypothesis, evidence of bad research practice, and a lack of reproducibility.</p>
<p>That being said, as editors have become more aware of the many issues with research misconduct, and with the growth of plagiarism detection software, the number of retractions across all of science have risen many fold. In the year 2000, there were about 100 retractions annually across all of science; in 2014 that number grew to 1,000; and in 2022 it was up to about 3,600.<span class="citation" data-cites="oransky_retractions_2022"><sup><a href="references.html#ref-oransky_retractions_2022" role="doc-biblioref">16</a></sup></span> <span class="citation" data-cites="brainard_what_2018"><sup><a href="references.html#ref-brainard_what_2018" role="doc-biblioref">17</a></sup></span> The largest and most comprehensive database of retractions (and one of my favorite websites) is <a href="https://retractionwatch.com">Retraction Watch</a>. If you’re reading this, stop reading right now and click on the link and check out Retraction Watch (consider also making a tax-deductible donation if you like the vibe).</p>
<p>So, why are so many papers being retracted? Though the graphic in <a href="#fig-rets">Figure&nbsp;<span>15.6</span></a> is a little older, it is still instructive.</p>
<div id="fig-rets" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/retractions.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.6: The majority of retractions between 1997 and 2015 have been due to fraud. These days, image fabrication is a particular problem in the STEM disciplines. <em>Science.</em><span class="citation" data-cites="brainard_what_2018"><sup><a href="references.html#ref-brainard_what_2018" role="doc-biblioref">17</a></sup></span></figcaption>
</figure>
</div>
<p>Plagiarism from other papers or even from one’s own previously published papers is one of the main culprits of retraction. Importantly, fake peer review has also been a driving factor behind retractions. Fake peer review happens when an author gives a journal an email address ostensibly as the contact for a potential reviewer, but in reality they control the email address. This means that they can control their own peer review, which defeats the purpose of the whole exercise. <a href="#fig-fakepeer">Figure&nbsp;<span>15.7</span></a> is what it can look like like when a paper is retracted because the editor discovered that the peer review process had been manipulated.</p>
<div id="fig-fakepeer" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/fakepeer.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.7: See the last sentence? This paper was retracted due to fake peer review.</figcaption>
</figure>
</div>
</section>
<section id="life-after-death-continued-citations-despite-retraction" class="level3" data-number="15.6.2">
<h3 data-number="15.6.2" class="anchored" data-anchor-id="life-after-death-continued-citations-despite-retraction"><span class="header-section-number">15.6.2</span> Life After Death: Continued Citations Despite Retraction</h3>
<p>Bad papers are being retracted at an increasing pace. That’s good, right? Yes. But, there is another problem. Many papers continue to be cited even years after they’ve been retracted, and most of the citations don’t mention that the paper has been retracted. Let’s look at the top five of the most highly cited retracted papers from Retraction Watch’s database, shown in <a href="#tbl-ret5">Table&nbsp;<span>15.1</span></a>.<span class="citation" data-cites="retraction_watch_top_2015"><sup><a href="references.html#ref-retraction_watch_top_2015" role="doc-biblioref">18</a></sup></span></p>
<div id="tbl-ret5" class="anchored">
<table class="table">
<caption>Table&nbsp;15.1: I’ve put links to the original articles instead of citing them, for obvious reasons.</caption>
<thead>
<tr class="header">
<th>Article title, journal, and year</th>
<th>Year of retraction</th>
<th>Citing articles before retraction</th>
<th>Citing articles after retraction</th>
<th>Total citations</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td><ol type="1">
<li><a href="https://www.nejm.org/doi/full/10.1056/NEJMoa1200303">Primary Prevention of Cardiovascular Disease with a Mediterranean Diet.</a> <em>New England Journal of Medicine</em>; 2013.</li>
</ol></td>
<td>2018</td>
<td>1,905</td>
<td>950</td>
<td>2,855</td>
</tr>
<tr class="even">
<td><ol start="2" type="1">
<li><a href="http://www.thelancet.com/pdfs/journals/lancet/PIIS0140-6736(97)11096-0.pdf">Ileal-lymphoid-nodular hyperplasia, non-specific colitis, and pervasive developmental disorder in children</a>. <em>Lancet</em>; 1998.</li>
</ol></td>
<td>2010</td>
<td>643</td>
<td>940</td>
<td>1,583</td>
</tr>
<tr class="odd">
<td><ol start="3" type="1">
<li><a href="https://science.sciencemag.org/content/307/5708/426.long">Visfatin: A protein secreted by visceral fat that mimics the effects of insulin</a>. <em>Science</em>; 2005.</li>
</ol></td>
<td>2007</td>
<td>232</td>
<td>1,232</td>
<td>1,464</td>
</tr>
<tr class="even">
<td><ol start="4" type="1">
<li><a href="http://onlinelibrary.wiley.com/doi/10.1046/j.1365-313X.2003.01676.x/abstract">An enhanced transient expression system in plants based on suppression of gene silencing by the p19 protein of tomato bushy stunt virus</a>. <em>The Plant Journal</em>; 2003.</li>
</ol></td>
<td>2015</td>
<td>895</td>
<td>421</td>
<td>1,316</td>
</tr>
<tr class="odd">
<td><ol start="5" type="1">
<li><a href="https://www.nature.com/articles/nature04695?proof=t">Lysyl oxidase is essential for hypoxia-induced metastasis.</a> <em>Nature</em>; 2006.</li>
</ol></td>
<td>2020</td>
<td>977</td>
<td>105</td>
<td>1,082</td>
</tr>
</tbody>
</table>
</div>
<p>Do you see how entries 2 and 3 have more citations after being retracted, than they did before retraction? That’s a problem! Additionally, entry 2 is fraudulent study claiming that vaccines cause autism. While this study has been thoroughly debunked, it has fueled the anti-vaccination movement, and its effects continue to be seen today. In this way, research misconduct does not just affect science, but can have massive downstream effects upon society, and the health and well-being of many.</p>
<p>Retraction does appear to decrease citation frequency, but not by as much as we might like. One study examined compared the citation counts for 3,000 retracted papers to 3,000 non-retracted papers.<span class="citation" data-cites="kuhberger_self-correction_2022"><sup><a href="references.html#ref-kuhberger_self-correction_2022" role="doc-biblioref">19</a></sup></span> They found that retraction decreased citation frequency by about 60%, and that many retracted papers continued to be cited.</p>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Perpetuation of Fraud: The Case of Scott Reuben
</div>
</div>
<div class="callout-body-container callout-body">
<p>On February 21, 2010 American anesthesiologist Scott Reuben formally pled guilty to one count of health care fraud. He was sentenced to six months in prison, followed by three years of supervised release. He also had to pay a $5,000 fine, forfeit $50,000 to the government, and make restitution to pharmaceutical companies he had defrauded to the tune of $360,000.</p>
<p>Reuben was formerly a professor of anesthesiology and pain medicine at Tufts University. He admitted to having faking data underlying his research, and lied about conducting 21 clinical trials. The fake results from these trials were published in many journals. When he was outed as a fraud, his publications had been cited almost 1,200 times, and his work was quoted in clinical guidelines. An analysis of his published work in 2014 revealed that 45% of his retracted articles had been cited at least once, and of these, only a quarter correctly mentioned the work as being retracted. Thus, even five years after his articles were retracted, they were still being quoted and cited.<span class="citation" data-cites="bornemann-cimenti_perpetuation_2016"><sup><a href="references.html#ref-bornemann-cimenti_perpetuation_2016" role="doc-biblioref">20</a></sup></span></p>
<p>Reuben was also able to slip past peer review and maintain fraudulent practices for 13 years, and wasted millions of dollars of funding. Consider also the impact his bogus findings had on the field of anesthesiology. At the time of the scandal, the editor-in-chief of the journal <em>Anesthesia and Analgesia</em> said of Reuben’s articles:</p>
<blockquote class="blockquote">
<p>We are left with a large hole in our understanding of this field. There are substantial tendrils from this body of work that reach throughout the discipline of postoperative pain management. Those tendrils mean that almost every aspect will need to be carefully thought through. What do we still believe to be true? Do the conclusions hold up to scrutiny?<span class="citation" data-cites="gorski_when_2009"><sup><a href="references.html#ref-gorski_when_2009" role="doc-biblioref">21</a></sup></span></p>
</blockquote>
</div>
</div>
<p>You may be wondering, why do people cite retracted studies? It’s usually not to call them out as retracted. The reality is that most folks don’t care to check or don’t know that a study is retracted. Retraction notices on journals also vary widely, with some being more salient than others. Let’s have a look at some retraction notices.</p>
<p>First up, we have the prestigious <em>New England Journal of Medicine</em> in <a href="#fig-nejmret">Figure&nbsp;<span>15.8</span></a>. This isn’t a great retraction notice because it’s just a narrow banner. These days, someone might mistake it for a pop-up about cookies, which has become ubiquitous. If someone downloads this in a hurry, I would worry that they might not see the notice.</p>
<div id="fig-nejmret" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/nejmret.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.8: The retraction notice isn’t very salient. If someone is downloading this in a hurry, will they notice?</figcaption>
</figure>
</div>
<p>Next, we’ve got <em>Science</em> in <a href="#fig-scienceret">Figure&nbsp;<span>15.9</span></a>. This one is bit more prominent, but could still be missed by someone in a hurry. We may also wonder, why not splash it against the title of the study?</p>
<div id="fig-scienceret" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/scienceret.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.9: Better than NEJM’s retraction notice maybe? Still, could be better and more prominent.</figcaption>
</figure>
</div>
<p>Finally, my favorite one so far is the retraction notice of the <em>Lancet</em>, shown in <a href="#fig-lancetret">Figure&nbsp;<span>15.10</span></a>. This is nice! It’s a huge notice splashed against the entire page. You cannot miss it. To me, this is the gold standard of retraction notices.</p>
<div id="fig-lancetret" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/lancetret.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.10: Now THAT’S a retraction notice!</figcaption>
</figure>
</div>
<p>Despite journal websites having retraction notices, some may still not be aware of the retractions because they might have downloaded the paper earlier pre-retraction. Thus, they might not need to ever visit the paper’s journal page, and may miss the retraction notice.</p>
<p>This is a big problem related to continued citation of retracted papers. One excellent solution to the problem exists IF you use Zotero for reference management. Zotero is a free reference management software, and now partners with Retraction Watch. This means that if a paper is in Retraction Watch’s database, it will show up as retracted in your Zotero. In <a href="#fig-zoteroret">Figure&nbsp;<span>15.11</span></a> you can see a screenshot of my Zotero, showing two papers that were retracted. The panel on the right explains why it was retracted, and a simple red cross gives me a quick indication that these papers have been retracted.</p>
<div id="fig-zoteroret" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="Images/zoteroret.png" class="img-fluid figure-img"></p>
<figcaption class="figure-caption">Figure&nbsp;15.11: A nice and easy notice of retraction. Thanks Zotero &amp; Retraction Watch!</figcaption>
</figure>
</div>


<div id="refs" class="references csl-bib-body" role="list" style="display: none">
<div id="ref-ioannidis_why_2005" class="csl-entry" role="listitem">
<div class="csl-left-margin">1. </div><div class="csl-right-inline">Ioannidis JPA. Why <span>Most</span> <span>Published</span> <span>Research</span> <span>Findings</span> <span>Are</span> <span>False</span>. <em>PLOS Medicine</em>. 2005;2(8):e124. doi:<a href="https://doi.org/10.1371/journal.pmed.0020124">10.1371/journal.pmed.0020124</a></div>
</div>
<div id="ref-engber_daryl_2017" class="csl-entry" role="listitem">
<div class="csl-left-margin">2. </div><div class="csl-right-inline">Engber D. Daryl <span>Bem</span> <span>Proved</span> <span>ESP</span> <span>Is</span> <span>Real</span>. <em>Slate</em>. Published online June 2017. Accessed July 13, 2023. <a href="https://slate.com/health-and-science/2017/06/daryl-bem-proved-esp-is-real-showed-science-is-broken.html">https://slate.com/health-and-science/2017/06/daryl-bem-proved-esp-is-real-showed-science-is-broken.html</a></div>
</div>
<div id="ref-kekecs_raising_2023" class="csl-entry" role="listitem">
<div class="csl-left-margin">3. </div><div class="csl-right-inline">Kekecs Z, Palfi B, Szaszi B, et al. Raising the value of research studies in psychological science by increasing the credibility of research reports: The transparent <span>Psi</span> project. <em>Royal Society Open Science</em>. 2023;10(2):191375. doi:<a href="https://doi.org/10.1098/rsos.191375">10.1098/rsos.191375</a></div>
</div>
<div id="ref-bem_feeling_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">4. </div><div class="csl-right-inline">Bem D, Tressoldi P, Rabeyron T, Duggan M. Feeling the future: <span>A</span> meta-analysis of 90 experiments on&nbsp;the anomalous anticipation of random future events. <em>F1000Research</em>. 2016;4:1188. doi:<a href="https://doi.org/10.12688/f1000research.7177.2">10.12688/f1000research.7177.2</a></div>
</div>
<div id="ref-lakens_20_2014" class="csl-entry" role="listitem">
<div class="csl-left-margin">5. </div><div class="csl-right-inline">Lakens D. The 20% <span>Statistician</span>: <span>A</span> pre-publication peer-review of the ’<span>Feeling</span> <span>The</span> <span>Future</span>’ meta-analysis. <em>The 20% Statistician</em>. Published online May 2014. Accessed July 14, 2023. <a href="http://daniellakens.blogspot.com/2014/05/a-pre-publication-peer-review-of-meta.html">http://daniellakens.blogspot.com/2014/05/a-pre-publication-peer-review-of-meta.html</a></div>
</div>
<div id="ref-simmons_false-positive_2011" class="csl-entry" role="listitem">
<div class="csl-left-margin">6. </div><div class="csl-right-inline">Simmons JP, Nelson LD, Simonsohn U. False-<span>Positive</span> <span>Psychology</span>: <span>Undisclosed</span> <span>Flexibility</span> in <span>Data</span> <span>Collection</span> and <span>Analysis</span> <span>Allows</span> <span>Presenting</span> <span>Anything</span> as <span>Significant</span>. <em>Psychological Science</em>. 2011;22(11):1359-1366. doi:<a href="https://doi.org/10.1177/0956797611417632">10.1177/0956797611417632</a></div>
</div>
<div id="ref-bargh_automaticity_1996" class="csl-entry" role="listitem">
<div class="csl-left-margin">7. </div><div class="csl-right-inline">Bargh JA, Chen M, Burrows L. Automaticity of social behavior: <span>Direct</span> effects of trait construct and stereotype activation on action. <em>Journal of personality and social psychology</em>. 1996;71(2):230.</div>
</div>
<div id="ref-doyen_behavioral_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">8. </div><div class="csl-right-inline">Doyen S, Klein O, Pichon CL, Cleeremans A. Behavioral <span>Priming</span>: <span>It</span>’s <span>All</span> in the <span>Mind</span>, but <span>Whose</span> <span>Mind</span>? <em>PLOS ONE</em>. 2012;7(1):e29081. doi:<a href="https://doi.org/10.1371/journal.pone.0029081">10.1371/journal.pone.0029081</a></div>
</div>
<div id="ref-schimmack_replicability_2019" class="csl-entry" role="listitem">
<div class="csl-left-margin">9. </div><div class="csl-right-inline">Schimmack U. Replicability <span>Audit</span> of <span>John</span> <span>A</span>. <span>Bargh</span>. <em>Replicability-Index</em>. Published online March 2019. Accessed July 14, 2023. <a href="https://replicationindex.com/2019/03/17/raudit-bargh/">https://replicationindex.com/2019/03/17/raudit-bargh/</a></div>
</div>
<div id="ref-yong_failed_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">10. </div><div class="csl-right-inline">Yong E. A failed replication draws a scathing personal attack from a psychology professor. <em>Science</em>. Published online March 2012. Accessed July 14, 2023. <a href="https://www.nationalgeographic.com/science/article/failed-replication-bargh-psychology-study-doyen">https://www.nationalgeographic.com/science/article/failed-replication-bargh-psychology-study-doyen</a></div>
</div>
<div id="ref-schimmack_meta-scientific_2020" class="csl-entry" role="listitem">
<div class="csl-left-margin">11. </div><div class="csl-right-inline">Schimmack U. A <span>Meta</span>-<span>Scientific</span> <span>Perspective</span> on “<span>Thinking</span>: <span>Fast</span> and <span>Slow</span>. <em>Replicability-Index</em>. Published online December 2020. Accessed July 18, 2023. <a href="https://replicationindex.com/2020/12/30/a-meta-scientific-perspective-on-thinking-fast-and-slow/">https://replicationindex.com/2020/12/30/a-meta-scientific-perspective-on-thinking-fast-and-slow/</a></div>
</div>
<div id="ref-open_science_collaboration_estimating_2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">12. </div><div class="csl-right-inline">Open Science Collaboration. Estimating the reproducibility of psychological science. <em>Science</em>. 2015;349(6251):aac4716. doi:<a href="https://doi.org/10.1126/science.aac4716">10.1126/science.aac4716</a></div>
</div>
<div id="ref-john_measuring_2012" class="csl-entry" role="listitem">
<div class="csl-left-margin">13. </div><div class="csl-right-inline">John LK, Loewenstein G, Prelec D. Measuring the <span>Prevalence</span> of <span>Questionable</span> <span>Research</span> <span>Practices</span> <span>With</span> <span>Incentives</span> for <span>Truth</span> <span>Telling</span>. <em>Psychological Science</em>. 2012;23(5):524-532. doi:<a href="https://doi.org/10.1177/0956797611430953">10.1177/0956797611430953</a></div>
</div>
<div id="ref-klein_many_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">14. </div><div class="csl-right-inline">Klein RA, Vianello M, Hasselman F, et al. Many <span>Labs</span> 2: <span>Investigating</span> <span>Variation</span> in <span>Replicability</span> <span>Across</span> <span>Samples</span> and <span>Settings</span>. <em>Advances in Methods and Practices in Psychological Science</em>. 2018;1(4):443-490. doi:<a href="https://doi.org/10.1177/2515245918810225">10.1177/2515245918810225</a></div>
</div>
<div id="ref-camerer_evaluating_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">15. </div><div class="csl-right-inline">Camerer CF, Dreber A, Holzmeister F, et al. Evaluating the replicability of social science experiments in <span>Nature</span> and <span>Science</span> between 2010 and 2015. <em>Nature Human Behaviour</em>. 2018;2(9):637-644. doi:<a href="https://doi.org/10.1038/s41562-018-0399-z">10.1038/s41562-018-0399-z</a></div>
</div>
<div id="ref-oransky_retractions_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">16. </div><div class="csl-right-inline">Oransky I. Retractions are increasing, but not enough. <em>Nature</em>. 2022;608(7921):9-9. doi:<a href="https://doi.org/10.1038/d41586-022-02071-6">10.1038/d41586-022-02071-6</a></div>
</div>
<div id="ref-brainard_what_2018" class="csl-entry" role="listitem">
<div class="csl-left-margin">17. </div><div class="csl-right-inline">Brainard J, You J. What a massive database of retracted papers reveals about science publishing’s <span>“death penalty.”</span> <em>Science</em>. 2018;25(1):1-5.</div>
</div>
<div id="ref-retraction_watch_top_2015" class="csl-entry" role="listitem">
<div class="csl-left-margin">18. </div><div class="csl-right-inline">Retraction Watch. Top 10 most highly cited retracted papers. <em>Retraction Watch</em>. Published online December 2015. Accessed July 19, 2023. <a href="https://retractionwatch.com/the-retraction-watch-leaderboard/top-10-most-highly-cited-retracted-papers/">https://retractionwatch.com/the-retraction-watch-leaderboard/top-10-most-highly-cited-retracted-papers/</a></div>
</div>
<div id="ref-kuhberger_self-correction_2022" class="csl-entry" role="listitem">
<div class="csl-left-margin">19. </div><div class="csl-right-inline">Kühberger A, Streit D, Scherndl T. Self-correction in science: <span>The</span> effect of retraction on the frequency of citations. <em>PLOS ONE</em>. 2022;17(12):e0277814. doi:<a href="https://doi.org/10.1371/journal.pone.0277814">10.1371/journal.pone.0277814</a></div>
</div>
<div id="ref-bornemann-cimenti_perpetuation_2016" class="csl-entry" role="listitem">
<div class="csl-left-margin">20. </div><div class="csl-right-inline">Bornemann-Cimenti H, Szilagyi IS, Sandner-Kiesling A. Perpetuation of <span>Retracted</span> <span>Publications</span> <span>Using</span> the <span>Example</span> of the <span>Scott</span> <span>S</span>. <span>Reuben</span> <span>Case</span>: <span>Incidences</span>, <span>Reasons</span> and <span>Possible</span> <span>Improvements</span>. <em>Science and Engineering Ethics</em>. 2016;22(4):1063-1072. doi:<a href="https://doi.org/10.1007/s11948-015-9680-y">10.1007/s11948-015-9680-y</a></div>
</div>
<div id="ref-gorski_when_2009" class="csl-entry" role="listitem">
<div class="csl-left-margin">21. </div><div class="csl-right-inline">Gorski D. When fraud undermines science-based medicine. <em>Science-Based Medicine</em>. Published online March 2009. Accessed July 19, 2023. <a href="https://sciencebasedmedicine.org/when-fraud-undermines-science-based-medicine/">https://sciencebasedmedicine.org/when-fraud-undermines-science-based-medicine/</a></div>
</div>
</div>
</section>
</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./replication3.html" class="pagination-link">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-number">14</span>&nbsp; <span class="chapter-title">Some Statistical Preliminaries</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./replication5.html" class="pagination-link">
        <span class="nav-page-text"><span class="chapter-number">16</span>&nbsp; <span class="chapter-title">Common Problems that Hamper Reproducibility</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->



</body></html>